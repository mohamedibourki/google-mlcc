# ğŸ“Š Linear Regression - ML Crash Course Summary

This module introduces the concept of **linear regression** in machine learning, a foundational technique for predicting a numeric value based on input features.

---

## ğŸ¯ Learning Objectives

- Understand **loss functions** and how they guide model training.
- Learn how **gradient descent** finds optimal parameters.
- Know how to **tune hyperparameters** for better performance.

---

## ğŸ“š Prerequisites

- Basic understanding of ML concepts from the **Introduction to Machine Learning** module.

---

## ğŸ§  Key Concepts

### What is Linear Regression?

Linear regression is a statistical method that models the relationship between a numeric **feature** (input) and a **label** (output) by fitting a straight line.

For example, to predict a carâ€™s fuel efficiency (MPG) based on its weight:

| Weight (1000s lbs) | MPG |
|--------------------|-----|
| 3.5                | 18  |
| 3.69               | 15  |
| 3.44               | 18  |
| 3.43               | 16  |
| 4.34               | 15  |
| 4.42               | 14  |
| 2.37               | 24  |

As car weight increases, fuel efficiency usually decreases â€” this forms a downward-sloping trend.

---

## ğŸ“ Model Equation

### Simple Linear Regression:

Å· = b + wâ‚xâ‚

Where:
- `Å·`: predicted output (e.g., MPG)
- `xâ‚`: input feature (e.g., weight)
- `wâ‚`: weight (slope of the line)
- `b`: bias (y-intercept)

#### Example:
If:
- `wâ‚ = -4.6`
- `b = 34`

Then, for a 4,000-pound car (i.e., `xâ‚ = 4`):

Å· = 34 + (-4.6 Ã— 4) = 15.6 MPG

---

## ğŸ§© Multiple Features

More realistic models use **multiple features**, each with its own weight:

Å· = b + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™

### For example:
To predict MPG, we might include:
- `xâ‚`: Engine displacement
- `xâ‚‚`: Acceleration
- `xâ‚ƒ`: Number of cylinders
- `xâ‚„`: Horsepower

Each feature contributes to the output based on its weight:

Å· = b + wâ‚(displacement) + wâ‚‚(acceleration) + wâ‚ƒ(cylinders) + wâ‚„(horsepower)

Some features have a negative relationship (e.g., horsepower), while others might be positive (e.g., acceleration time).

---

## ğŸ” Training the Model

During training, the algorithm adjusts the **weights** and **bias** to minimize prediction error using:

- A **loss function** (measures how bad the prediction is)
- **Gradient descent** (an optimization algorithm to minimize the loss)

Only the **weights** and **bias** are updated during training â€” not the input features or output labels.

---

## âœ… Exercise Check

**Question:** What parts of the linear regression equation are updated during training?  
**Answer:** âœ… **Bias and Weights**

---

## ğŸ§¾ Key Terms

- **Feature**: An input variable (e.g., weight, horsepower)
- **Label**: The output you want to predict (e.g., MPG)
- **Weight**: Coefficient representing feature importance
- **Bias**: Constant added to the prediction (intercept)
- **Parameter**: Tunable values in the model (weights and bias)
- **Linear Regression**: Predicts continuous output using a weighted sum of input features

---
